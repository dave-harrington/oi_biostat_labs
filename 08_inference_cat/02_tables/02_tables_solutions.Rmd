---
title: "Inference for Two-Way Tables"
author: "Chapter 8, Lab 2: Solutions"
date: "OpenIntro Biostatistics"

fontsize: 11pt
geometry: margin=1in

output:
  pdf_document:
    includes:
      in_header: ../../header.tex
    fig_width: 5
    fig_height: 3.5
---

\begin{small}
	
	\textbf{Topics}
	\begin{itemize}
	  \item The $\chi^2$ test for independence
	  \item Fisher's exact test
	  \item Measures of association in two-by-two tables
	\end{itemize}
	
\end{small}

This lab generalizes inference for binomial proportions to the setting of two-way contingency tables. Hypothesis testing in a two-way table assesses whether the two variables of interest are associated; this approach can be applied to settings with two or more groups and for responses that have two or more categories. Measures of association in two-by-two tables are also discussed.

The material in this lab corresponds to Sections 8.3 and 8.5 in *OpenIntro Biostatistics*.

### Introduction

*The $\chi^2$ test of independence*

In the $\chi^2$ test of independence, the observed number of cell counts are compared to the number of **expected** cell counts, where the expected counts are calculated under the null hypothesis.

  - $H_0$: the row and column variables are not associated

  - $H_A$: the row and column variables are associated

The expected count for the $i^{th}$ row and $j^{th}$ column is
\[E_{i, j} = \dfrac{(\text{row $i$ total}) \times (\text{column $j$ total}) }{n}, \]
where $n$ is the total number of observations.

Assumptions for the $\chi^2$ test:

  - *Independence*. Each case that contributes a count to the table must be independent of all other cases in the table.
  
  - *Sample size*. Each expected cell count must be greater than or equal to 10. For tables larger than $2 \times 2$, it is appropriate to use the test if no more than 1/5 of the expected counts are less than 5, and all expected counts are greater than 1.

The **$\chi^2$ test statistic** is calculated as
\[\chi^2 = \sum_{i = 1}^r \sum_{j = 1}^c \dfrac{(O_{i, j} - E_{i, j})^2}{E_{i, j}}, \]
and is approximately distributed $\chi^2$ with degrees of freedom $(r - 1)(c - 1)$, where $r$ is the number of rows and $c$ is the number of columns. $O_{i, j}$ represents the observed count in row $i$, column $j$.

For each cell in a table, the **residual** equals
\[\dfrac{O_{i, j} - E_{i, j}}{\sqrt{E_{i,j}}}. \]
Residuals with a large magnitude contribute the most to the $\chi^2$ statistic. If a residual is positive, the observed value is greater than the expected value; if a residual is negative, the observed value is less than the expected.

\vspace{0.5cm}

*Fisher's exact test*

When the expected counts in a two-way table are less than 10, Fisher's exact test is used to compute a $p$-value without relying on the normal approximation. In this course, only the logic behind Fisher's exact test for a $2 \times 2$ table is discussed. In the $2 \times 2$ table case, the hypotheses for Fisher's exact test can be expressed in the same way as for a two-sample test of proportions; the null hypothesis is $H_0: p_1 = p_2$.

The $p$-value is the probability of observing results as or more extreme than those observed under the assumption that the null hypothesis is true.

  - Thus, the $p$-value is calculated by adding together the individual conditional probabilities of obtaining each table that is as or more extreme than the one observed, under the null hypothesis and given that the marginal totals are considered fixed.
  
  - When the marginal totals are held constant, the value of any one cell in the table determines the rest of entries. When marginal totals are considered fixed, each table represents a unique set of results.
  
  - Extreme tables are those which contradict $H_0: p_1 = p_2$.
  
  - A two-sided $p$-value can be calculated by doubling the smaller of the possible one-sided $p$-values; this method is typically used when calculating $p$-values by hand. Another common method is to classify "more extreme" tables as all tables with probabilities less than that of the observed table, in both directions; the $p$-value is the sum of probabilities for the qualifying table.
  
The probability of a particular table (i.e., set of results) can be calculated with the **hypergeometric distribution**.

Let $X$ represent the number of successes in a series of repeated Bernoulli trials, where sampling is done without replacement. Suppose that in the population of size $N$, there are $m$ total successes. What is the probability of observing exactly $k$ successes when drawing a sample of size $n$?


For example, imagine an urn with $m$ white balls and $N - m$ black balls (thus, there are $N$ total balls). Draw $n$ balls without replacement (i.e., a sample of $n$ balls). What is the probability of observing $k$ white balls in the sample? 

The possible results of a sample can be organized in a $2 \times 2$ table:

\begin{table*}[h!]
\begin{center}
\begin{tabular}{l|cc|c} 
   & \textbf{White Ball} & \textbf{Black Ball} & \textbf{Total}\\ \hline
  \textbf{Sampled} & $k$ & \textcolor{gray}{$n - k$}  & $n$  \\
  \textbf{Not Sampled} & \textcolor{gray}{$m - k$} & \textcolor{gray}{$N - n - (m - k)$} & \textcolor{gray}{$N - n$} \\ \hline
  \textbf{Total} & $m$ & $N - m$ & $N$  \\ 
\end{tabular}\\
\end{center}
\end{table*}


The probability of observing exactly $k$ successses in a sample of size $n$ (i.e., $n$ dependent trials) is given by 
\[P(X = k) = \dfrac{{m \choose k} {N - m \choose n-k}}{{N \choose n}}. \]

Hypergeometric probabilities are calculated in \textsf{R} with the use of \texttt{dhyper()} and \texttt{phyper()}. The following code shows how to calculate $P(X = 5)$, $P(X \leq 5)$, and $P(X > 5)$ for $X \sim \text{HGeom}(10, 15, 8)$, where $m = 10$, $N - m = 15$, and $n = 8$. 

```{r}
#probability X equals 5
dhyper(5, 10, 15, 8)

#probability X is less than or equal to 5
phyper(5, 10, 15, 8)

#probability X is greater than 5
phyper(5, 10, 15, 8, lower.tail = FALSE)
```

\vspace{0.5cm}

*Measures of association in two-by-two tables*

Chapter 1 introduced the **relative risk (RR)**, a measure of the risk of a certain event occurring in one group relative to the risk of the event occurring in another group, as a numerical summary for two-by-two ($2 \times 2$) tables. The relative risk can also be thought of as a measure of association.

Consider the following hypothetical two-by-two table. The relative risk of Outcome A can be calculated by using either Group 1 or Group 2 as the reference group:

\begin{table}[h!]
	\centering
	\begin{tabular}{r|rrr}
		\hline
		& Outcome A & Outcome B & Sum\\ 
		\hline
		Group 1 & $a$ & $b$ & $a + b$ \\ 
		Group 2 & $c$ & $d$ & $c + d$ \\
		Sum & $a + c$ & $b + d$ & $a + b + c + d = n$ \\
		\hline
	\end{tabular}	
	\caption{A hypothetical two-by-two table of outcome by group.}
\end{table}


\[RR_{\text{A, comparing Group 1 to Group 2}} = \dfrac{a/(a + b)}{c/(c+d)} \]
\[RR_{\text{A, comparing Group 2 to Group 1}} = \dfrac{c/(c + d)}{a/(a+b)} \]

The relative risk is only valid for tables where the proportions $a/(a + b)$ and $c/(c + d)$ represent the incidence of Outcome A within the populations from which Groups 1 and 2 are sampled.

The **odds ratio (OR)** is a measure of association that remains applicable even when it is not possible to estimate incidence of an outcome from the sample data. The **odds** of Outcome A in Group 1 are $a/b$, while the odds of Outcome A in Group 2 are $c/d$.

\[OR_{\text{A, comparing Group 1 to Group 2}} = \dfrac{a/b}{c/d} = \dfrac{ad}{bc} \]
\[OR_{\text{A, comparing Group 2 to Group 1}} = \dfrac{c/d}{a/b} = \dfrac{bc}{ad} \]

\vspace{0.5cm}

### The $\chi^2$ test of independence

1. In resource-limited settings, single-dose nevirapine (NVP) is given to an HIV-positive woman during birth to prevent mother-to-child transmission of the virus. Exposure of the infant to NVP may foster the growth of more virulent strains of the virus in the child.

    If a child is HIV-positive, should they be treated with NVP or a more expensive drug, lopinavir (LPV)? In this setting, success means preventing a growth of the virus in the child (i.e., preventing virologic failure). The following table contains data from a 2012 study conducted in six African countries and India.\footnote{A. Violari, et al. "Nevirapine versus ritonavir-boosted lopinavir for HIV-infected children." \textit{NEJM} 366: 2380-2389.}
    
    \begin{center}
\begin{tabular}{l|cc|c} 
   & \textbf{NVP} & \textbf{LPV} & \textbf{Total}\\ \hline
  \textbf{Virologic Failure} & 60 & 27 & 87  \\
  \textbf{Stable Disease} & 87 & 113 & 200 \\ \hline
  \textbf{Total} & 147 & 140 & 287  \\ 
\end{tabular}\\
\end{center}

    \vspace{0.5cm}
    
    a) State the null and alternative hypotheses.

        \color{NavyBlue}
  
        The null hypothesis is that there is no association between treatment and outcome; i.e., treatment and outcome are independent.
  
        The alternative hypothesis is that there is an association between treatment and outcome; i.e., treatment and outcome are not independent.
  
        \color{Black}


    
    b) Calculate the expected cell counts.
    
        \color{NavyBlue}  
    
        The expected cell counts are shown in parentheses next to the observed cell counts.  
    
        \begin{center}
  \begin{tabular}{l|cc|c} 
   & \textbf{NVP} & \textbf{LPV} & \textbf{Total}\\ \hline
  \textbf{Virologic Failure} & 60 (44.56) & 27 (42.44) & 87  \\ 
  \textbf{Stable Disease} & 87 (102.44) & 113 (97.56)& 200 \\ \hline
  \textbf{Total} & 147 & 140 & 287  \\ 
  \end{tabular}\\
        \end{center}  


        \color{Black}

    ```{r}
#use r as a calculator

#set parameters
n = 287
row.1.total = 87
row.2.total = 200
col.1.total = 147
col.2.total = 140

#calculate expected values
exp.1.1 = (row.1.total * col.1.total)/n
exp.1.1

exp.1.2 = (row.1.total * col.2.total)/n
exp.1.2

exp.2.1 = (row.2.total * col.1.total)/n
exp.2.1

exp.2.2 = (row.2.total * col.2.total)/n
exp.2.2
```

    
    c) Check the assumptions for using the $\chi^2$ test.

        \textcolor{NavyBlue}{Independence holds, since this is a randomized study. All expected counts are greater than 10.}

    d) Calculate the $\chi^2$ test statistic.
    
        \color{NavyBlue}
  
        \[\chi^2 = \sum \dfrac{(\text{obs - exp})^2}{\text{exp}} = \dfrac{(60-44.56)^2}{44.56} + \dfrac{(27-42.44)^2}{42.44} +  \dfrac{(87-102.44)^2}{102.44} + \dfrac{(113 - 97.56)^2}{97.56} = 15.74\]
  
        \color{Black}

    ```{r}
#use r as a calculator
obs.1.1 = 60
chi.sq.1.1 = ((obs.1.1 - exp.1.1)^2)/exp.1.1

obs.1.2 = 27
chi.sq.1.2 = ((obs.1.2 - exp.1.2)^2)/exp.1.2

obs.2.1 = 87
chi.sq.2.1 = ((obs.2.1 - exp.2.1)^2)/exp.2.1

obs.2.2 = 113
chi.sq.2.2 = ((obs.2.2 - exp.2.2)^2)/exp.2.2

chi.sq = chi.sq.1.1 + chi.sq.1.2 + chi.sq.2.1 + chi.sq.2.2
chi.sq
```



    e) Calculate the $p$-value for the test statistic using \texttt{pchisq()}. The $p$-value represents the probability of observing a result as or more extreme than the sample data.

        \textcolor{NavyBlue}{The $p$-value for the test statistic is $7.28 \times 10^{-5}$.}


    ```{r, eval = FALSE}
#use pchisq()
pchisq(chi.sq, df = (2 - 1)*(2 - 1), lower.tail = FALSE)
```

    
    f) Confirm the results from parts c) and d) using \texttt{chisq.test()}. Note that the value of the test statistic will be slightly different because \textsf{R} is applying a 'continuity correction'.
    
        \textcolor{NavyBlue}{From \texttt{chisq.test()}, the $\chi^2$ statistic is 14.73 and the associated $p$-value is 0.0001.}

    ```{r}
#enter the data as a table
hiv.table = matrix(c(60, 27, 87, 113), 
                  nrow = 2, ncol = 2, byrow = T)
    
#add labels and confirm the table was entered correctly
dimnames(hiv.table) = list("Outcome" = c("Virologic Failure", "Stable Disease"),
                            "Drug" = c("NVP", "LPV"))
hiv.table

#use chisq.test()
chisq.test(hiv.table)
```

    
    g) Summarize the conclusions; be sure to include which drug is recommended for treatment, based on the data.

        \color{NavyBlue}
  
          There is sufficient evidence at the $\alpha = 0.05$ significance level to reject the null hypothesis and accept the alternative hypothesis that treatment and outcome are associated.
  
          From comparing the expected and observed cell counts (or looking at the residuals), it is possible to determine the direction of the association. When treated with lopinarvir, fewer children than expected experience virologic failure (27 observed versus ~42 expected), and more than expected experience stable disease (113 observed versus ~98 expected). In contrast, when treated with nevirapine, more children than expected experience virologic failure (60 observed versus ~45 expected), and fewer children than expected experience stable disease (87 observed versus ~102 expected). 
  
          The data suggest that HIV-positive children should be treated with lopinarvir.
  
          \color{Black}


    ```{r}
#look at residuals
chisq.test(hiv.table)$resid

#to view the expected values, use $expected
chisq.test(hiv.table)$expected
```

    
    h) Repeat the analysis using inference for the difference of two proportions and confirm that the results are the same.

        \textcolor{NavyBlue}{The proportion of successes on nevirapine is 0.59 and the proportion of successes on lopinarvir is 0.81. The $p$-value is 0.0012; there is sufficient evidence to reject the null of no difference and conclude that stable disease is associated with lopinarvir.}

    ```{r}
#use prop.test( )
prop.test(x = c(87, 113), n = c(147, 140))
```

    
2. In the PREVEND study introduced in Chapter 6, researchers measured various features of study participants, including data on statin use and highest level of education attained. From the data in \texttt{prevend.samp}, is there evidence of an association between statin use and educational level? Summarize the results.

    \color{NavyBlue}

    Test the null hypothesis that statin use and education level are not associated against the alternative hypothesis that statin use and education level are associated. Let $\alpha = 0.05$.

    The $p$-value of the $\chi^2$ statistic is 0.0003. The results are highly significant, and there is evidence to support accepting the alternative hypothesis that statin use and education level are associated.

    The largest deviations from independence occur in the primary school group and university group. There are more statin users than expected in the primary school group and fewer statin users than expected in the university group. There is an observable overall trend; as highest educational level attained increases, the proportion of statin users goes from higher than expected to lower than expected.

    \color{Black}

    ```{r}
#load the data
library(oibiostat)
data("prevend.samp")

#convert variables to factors
prevend.samp$Statin = factor(prevend.samp$Statin, levels = c(0, 1),
                             labels = c("NonUser", "User"))

prevend.samp$Education = factor(prevend.samp$Education, levels = 0:3,
                                labels = c("Primary", "LowerSec",
                                           "UpperSec", "Univ"))

#create a table
statin.edu.table = table(prevend.samp$Statin, prevend.samp$Education)

#run chi-squared test
chisq.test(statin.edu.table)

chisq.test(statin.edu.table)$residuals
```

\newpage

### Fisher's exact test

3. \textit{Clostridium difficile} is a bacterium that causes inflammation of the colon. Antibiotic treatment is typically not effective, particularly for patients who experience multiple recurrences of infection. Infusion of feces from healthy donors has been reported as an effective treatment for recurrent infection. A randomized trial was conducted to compare the efficacy of donor-feces infusion versus vancomycin, the antibiotic typically prescribed to treat \textit{C. difficile }infection. The results of the trial are shown in the following table. 

    \begin{table}[h]
	\centering
	\begin{tabular}{rrr|r}
		\hline
		& Cured & Uncured & Sum \\ 
		\hline
		Fecal Infusion & 13 & 3 & 16 \\ 
		Vancomycin & 4 & 9 & 13 \\ 
		\hline
		Sum & 17 & 12 & 29 \\ 
		\hline
	\end{tabular}
    \end{table}

    a) Can a $\chi^2$ test be used to analyze these results?
    
        \textcolor{NavyBlue}{A $\chi^2$ test is not advisable since there are expected counts less than 10.}
    
    ```{r}
infusion.table = matrix(c(13, 3, 4, 9), nrow = 2, ncol = 2, byrow = T)
dimnames(infusion.table) = list("Outcome" = c("Cured", "Uncured"),
                                "Treatment" = c("Fecal Infusion", 
                                                "Vancomycin"))

chisq.test(infusion.table)$expected
```
    
    b) Researchers are interested in understanding whether fecal infusion is a more effective treatment than vancomycin. Write the null hypothesis and appropriate one-sided alternative hypothesis.
    
        \textcolor{NavyBlue}{Let $p_1$ represent the population proportion of individuals cured on the fecal infusion treatment and $p_2$ represent the population proportion of individuals cured on the vancomycin treatment. Under the null hypothesis, the proportion cured is equal between the two treatment groups: $H_0: p_1 = p_2$. The appropriate alternative hypothesis of interest is $H_0: p_1 > p_2$. }    
    
    c) Under the assumption that the marginal totals are fixed, enumerate all possible sets of results that are more extreme than what was observed, in the same direction.
    
        \textcolor{NavyBlue}{Results more extreme than what was observed are those that constitute stronger evidence in favor of the fecal treatment group being more effective than vancomyin; i.e., results where either 14, 15, or 16 of the cured patients were in the fecal infusion group.}
      
        \color{NavyBlue}
      
        \begin{table}[h]
	\centering
	\color{gray}
	\begin{tabular}{r|cc|c}
		\hline
		& Cured & Uncured & Sum \\ 
		\hline
		Fecal Infusion & \textcolor{black}{14} & \textcolor{black}{2} & 16 \\ 
		Vancomycin & \textcolor{black}{3} & \textcolor{black}{10} & 13 \\ 
		\hline
		Sum & 17 & 12 & 29 \\ 
		\hline
	\end{tabular}
        \end{table}

        \begin{table}[h]
	\centering
	\color{gray}
	\begin{tabular}{r|cc|c}
		\hline
		& Cured & Uncured & Sum \\ 
		\hline
		Fecal Infusion & \textcolor{black}{15} & \textcolor{black}{1} & 16 \\ 
		Vancomycin & \textcolor{black}{2} & \textcolor{black}{11} & 13 \\ 
		\hline
		Sum & 17 & 12 & 29 \\ 
		\hline
	\end{tabular}
        \end{table}

        \begin{table}[h]
	\centering
	\color{gray}
	\begin{tabular}{r|cc|c}
		\hline
		& Cured & Uncured & Sum \\ 
		\hline
		Fecal Infusion & \textcolor{black}{16} & \textcolor{black}{0} & 16 \\ 
		Vancomycin & \textcolor{black}{1} & \textcolor{black}{12} & 13 \\ 
		\hline
		Sum & 17 & 12 & 29 \\ 
		\hline
	\end{tabular}
      \end{table}
      
      \color{Black}
    
    d) Calculate the probability of the observed results.
    
        \textcolor{NavyBlue}{Use the hypergeometric distribution with parameters $N = 29$, $m = 17$, and $n = 16$; calculate $P(X = 13)$. Consider the "successes" to be the individuals cured and the "sample size" to be the number of individuals in the fecal infusion group. The probability that 13 of the cured individuals were in the fecal infusion group, given the table margins are fixed, is 0.0077.}
    
    ```{r}
#probability of the observed results
dhyper(13, 17, 29 - 17, 16)
```

    
    e) Calculate the probability of each set of results enumerated in part c).
    
        \textcolor{NavyBlue}{The probabilities of observing 14, 15, or 16 cured individuals in the fecal infusion group, respectively, are $6.61 \times 10^{-4}$, $2.41 \times 10^{-5}$, and $2.51 \times 10^{-7}$. }
    
    ```{r}
#probability of results more extreme than observed
dhyper(14, 17, 29 - 17, 16)
dhyper(15, 17, 29 - 17, 16)
dhyper(16, 17, 29 - 17, 16)
```
    
    f) Based on the answers in parts d) and e), compute the one-sided $p$-value and interpret the results.
    
        \textcolor{NavyBlue}{The probability of observing results as or more extreme than the observed table is 0.0084. Since $p < 0.05$, there is sufficient evidence to reject the null hypothesis at significance level $\alpha = 0.05$; the data support fecal infusion as a more effective treatment for \textit{C. difficile} infection than vancomycin.}
    
    ```{r}
#summing previous probabilities
p.observed = dhyper(13, 17, 29 - 17, 16)
p.more.extreme = dhyper(14, 17, 29 - 17, 16) + dhyper(15, 17, 29 - 17, 16) + 
  dhyper(16, 17, 29 - 17, 16)
p.observed + p.more.extreme

#using phyper
phyper(12, 17, 29 - 17, 16, lower.tail = FALSE)
```

    
    g) Use \texttt{fisher.test( )} to confirm the calculations in part f) and to calculate the two-sided $p$-value.
    
        \textcolor{NavyBlue}{The two-sided $p$-value is 0.0095.}
    
    ```{r}
#one-sided p-value
fisher.test(infusion.table, alternative = "greater")$p.val

#two-sided p-value
fisher.test(infusion.table, alternative = "two.sided")$p.val
```


4. Psychologists conducted an experiment to investigate the effect of anxiety on a person's desire to be alone or in the company of others (Schacter 1959; Lehmann 1975). A group of 30 individuals were randomly assigned into two groups; one group was designated the "high anxiety" group and the other the "low anxiety" group. Those in the high-anxiety group were told that in the "upcoming experiment", they would be subjected to painful electric shocks, while those in the low-anxiety group were told that the shocks would be mild and painless.\footnote{Individuals were not actually subjected to electric shocks of any kind}. All individuals were informed that there would be a 10 minute wait before the experiment began, and that they could choose whether to wait alone or with other participants.

    The following table summarizes the results:
  
    \begin{table}[h]
	\centering
	\begin{tabular}{rrr|r}
		\hline
		& Wait Together & Wait Alone & Sum \\ 
		\hline
		High-Anxiety & 12 & 5 & 17 \\ 
		Low-Anxiety & 4 & 9 & 13 \\ 
		\hline
		Sum & 16 & 14 & 30 \\ 
		\hline
	\end{tabular}
    \end{table}


    a) Under the null hypothesis of no association, what are the expected cell counts?
    
        \textcolor{NavyBlue}{Under the null hypothesis of no association, the expected cell counts are 9.07 and 7.93 in the wait together and wait alone groups, respectively, for those considered "high anxiety" and 6.93 and 6.07 in the wait together and wait alone groups, respectively, for those considered "low anxiety".}
    
    ```{r}
#enter the data
anxiety.table = matrix(c(12, 5, 4, 9), nrow = 2, ncol = 2, byrow = T)
dimnames(anxiety.table) = list("Treatment" = c("High Anxiety", "Low Anxiety"),
                               "Outcome" = c("Wait Together", "Wait Alone"))

chisq.test(anxiety.table)$expected
```
       
    
    b) Under the assumption that the marginal totals are fixed and the null hypothesis is true, what is the probability of the observed set of results?

        \textcolor{NavyBlue}{Use the hypergeometric distribution with parameters $N = 30$, $m = 16$, and $n = 17$; calculate $P(X = 12)$. Consider the "successes" to be the individuals who wait together, and the "number sampled" to be the people randomized to the high-anxiety group. The probability of the observed set of results, assuming the marginal totals are fixed and the null hypothesis is true, is 0.0304.}
    
    ```{r}
dhyper(12, 16, 30 - 16, 17)
```


    c) Enumerate the tables that are more extreme than what was observed, in the same direction. 
    
        \textcolor{NavyBlue}{More individuals than expected in the high-anxiety group were observed to wait together; thus, tables that are more extreme in the same direction also consist of those where more people in the high-anxiety group wait together than observed. These are tables in which 13, 14, 15, or 16 individuals in the high-anxiety group wait together.}
        
        \begin{table}[h]
	\centering
	\color{gray}
	\begin{tabular}{r|cc|c}
		\hline
		& Wait Together & Wait Alone & Sum \\ 
		\hline
		High-Anxiety & \textcolor{black}{13} & \textcolor{black}{4} & 17 \\ 
		Low-Anxiety & \textcolor{black}{3} & \textcolor{black}{10} & 13 \\ 
		\hline
		Sum & 16 & 14 & 30 \\ 
		\hline
	\end{tabular}
        \end{table}
        
        \begin{table}[h!]
	\centering
	\color{gray}
	\begin{tabular}{r|cc|c}
		\hline
		& Wait Together & Wait Alone & Sum \\ 
		\hline
		High-Anxiety & \textcolor{black}{14} & \textcolor{black}{3} & 17 \\ 
		Low-Anxiety & \textcolor{black}{2} & \textcolor{black}{11} & 13 \\ 
		\hline
		Sum & 16 & 14 & 30 \\ 
		\hline
	\end{tabular}
        \end{table}
        
        \begin{table}[h!]
	\centering
	\color{gray}
	\begin{tabular}{r|cc|c}
		\hline
		& Wait Together & Wait Alone & Sum \\ 
		\hline
		High-Anxiety & \textcolor{black}{15} & \textcolor{black}{2} & 17 \\ 
		Low-Anxiety & \textcolor{black}{1} & \textcolor{black}{12} & 13 \\ 
		\hline
		Sum & 16 & 14 & 30 \\ 
		\hline
	\end{tabular}
        \end{table}
        
        \begin{table}[h!]
	\centering
	\color{gray}
	\begin{tabular}{r|cc|c}
		\hline
		& Wait Together & Wait Alone & Sum \\ 
		\hline
		High-Anxiety & \textcolor{black}{16} & \textcolor{black}{1} & 17 \\ 
		Low-Anxiety & \textcolor{black}{0} & \textcolor{black}{13} & 13 \\ 
		\hline
		Sum & 16 & 14 & 30 \\ 
		\hline
	\end{tabular}
        \end{table}
    
    
    \newpage
    
    d) Conduct a formal test of association for the results and summarize your findings. Let $\alpha = 0.05$.
    
        \textcolor{NavyBlue}{Let $p_1$ represent the population proportion of individuals waiting together in the high-anxiety group and $p_2$ represent the population proportion of individuals waiting together in the low-anxiety group. Test $H_0: p_1 = p_2$ against $H_A: p_1 \neq p_2$. Let $\alpha = 0.05$. The two-sided $p$-value is 0.063. There is insufficient evidence to reject the null hypothesis; the data do not suggest there is an association between high anxiety and a person's desire to be in the company of others.}
        
        \textcolor{NavyBlue}{Note that the results are borderline; a one-sided $p$-value rejects the null hypothesis with $p = 0.036$. The choice of two-sided hypothesis is more impartial.}
        
    ```{r}
#two-sided test
fisher.test(anxiety.table)$p.val
    
#one-sided test
fisher.test(anxiety.table, alternative = "greater")$p.val
```
        
\newpage

### Measures of association in two-by-two tables

5. Suppose a study is conducted to assess the association between smoking and cardiovascular disease (CVD). Researchers recruited a group of 231 study participants then categorized them according to smoking and disease status: 111 are smokers, while 40 smokers and 32 non-smokers have CVD. Calculate and interpret the relative risk of CVD.

    \textcolor{NavyBlue}{The relative risk of CVD comparing smokers to non-smokers is 1.35. Smoking is associated with a 35\% increase in the probability of CVD. In other words, the risk of CVD is 35\% greater in smokers compared to non-smokers. }

    ```{r}
#use r as a calculator
risk.smokers = 40/111
risk.nonsmokers = 32/(231-111)

risk.smokers / risk.nonsmokers
```


6. Suppose another study is conducted to assess the association between smoking and CVD, but researchers use a different design: 90 individuals with CVD and 110 individuals without CVD are recruited. 40 of the individuals with CVD are smokers, and 80 of the individuals without CVD are non-smokers.

    a) Is relative risk an appropriate measure of association for these data? Explain your answer.
    
        \textcolor{NavyBlue}{No, relative risk should not be calculated for these observations. Since the number of individuals with and without CVD is fixed by the study design, the proportion of individuals with CVD within a certain group (smokers or non-smokers) as calculated from the data is not a measure of CVD risk for that population.}

    b) Calculate the odds of CVD among smokers and the odds of CVD among non-smokers.
    
        \textcolor{NavyBlue}{Since there are 110 individuals without CVD and 80 of those are non-smokers, there are 30 individuals without CVD who smoke. Thus, there are $30 + 40 = 70$ individuals who smoke, and $(110 + 90) - 70 = 130$ individuals who do smoke. Of the 130 non-smokers, 80 do not have CVD; thus, 50 non-smokers have CVD.} 
        
        \textcolor{NavyBlue}{The odds of CVD among smokers is the number of smokers with CVD divided by the number of smokers without CVD: $40/30 = 1.33$. The odds of CVD among non-smokers is the number of non-smokers with CVD divided by the number of non-smokers without CVD: $50/80 = 0.625$.}
    
    ```{r}
#use r as a calculator
odds.smokers = 40/30
odds.nonsmokers = 50/80

odds.smokers
odds.nonsmokers
```

    c) Calculate and interpret the odds ratio of CVD, comparing smokers to non-smokers.
  
        \textcolor{NavyBlue}{The odds ratio of CVD, comparing smokers to non-smokers is 2.13. The odds of CVD in smokers are approximately twice as large as the odds of CVD in smokers. The data suggest that smoking is associated with CVD.}
    

    ```{r}
#use r as a calculator
odds.smokers / odds.nonsmokers
```

    d) What would an odds ratio of CVD (comparing smokers to non-smokers) equal to 1 represent, in terms of the association between smoking and CVD? What would an odds ratio of CVD less than 1 represent?

        \textcolor{NavyBlue}{An odds ratio equal to 1 would represent no association between smoking and CVD. An odds ratio less than 1 would represent an association between not smoking and CVD; i.e., that the odds of CVD in non-smokers were higher than the odds of CVD in smokers.}


